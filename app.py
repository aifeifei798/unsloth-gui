"""
=====================================================================================
ğŸš€ Unsloth GUI Trainer: ä¸€ä¸ªä¸“ä¸šçš„äº¤äº’å¼å¾®è°ƒå·¥ä½œå° (v3.0 - æœ€ç»ˆæ–‡æ¡£ç‰ˆ) ğŸš€
=====================================================================================

æœ¬åº”ç”¨æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„å›¾å½¢åŒ–ç•Œé¢ï¼Œç”¨äºï¼š
1.  é€šè¿‡ JSON é…ç½®æ–‡ä»¶åŠ¨æ€åŠ è½½å’Œé€‰æ‹©æ¨¡å‹ä¸æ•°æ®é›†ã€‚
2.  æ”¯æŒåˆå¹¶å¤šä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬ä»æœ¬åœ°ç£ç›˜åŠ è½½ã€‚
3.  ç²¾ç»†åŒ–è°ƒæ•´ LoRA å’Œæ ¸å¿ƒè®­ç»ƒè¶…å‚æ•°ã€‚
4.  é€šè¿‡å”¯ä¸€çš„â€œå®éªŒåç§°â€ç®¡ç†è®­ç»ƒä»»åŠ¡ã€‚
5.  æ”¯æŒæŒ‰â€œè½®æ¬¡(Epoch)â€æˆ–â€œæ­¥æ•°(Step)â€ä¸¤ç§æ¨¡å¼è¿›è¡Œè®­ç»ƒå’Œä¿å­˜ã€‚
6.  æ”¯æŒä»æ–­ç‚¹å¤„æ— ç¼ç»§ç»­è®­ç»ƒã€‚
7.  é›†æˆ TensorBoardï¼Œå®æ—¶ã€å¯è§†åŒ–åœ°ç›‘æ§æ‰€æœ‰å®éªŒçš„è®­ç»ƒè¿‡ç¨‹ã€‚

æ–‡ä»¶ç»“æ„è¦æ±‚:
/
|-- app.py                 (æœ¬è„šæœ¬)
|-- models.json            (æ¨¡å‹é…ç½®æ–‡ä»¶)
|-- datasets_config/       (å­˜æ”¾æ•°æ®é›†é…ç½®çš„ç›®å½•)
|   |-- alpaca.json
|   |-- my_local_data.json
|   `-- ...
|-- outputs/               (å­˜æ”¾æ‰€æœ‰æ¨¡å‹è¾“å‡ºå’Œæ–­ç‚¹çš„çˆ¶ç›®å½•)
|-- logs/                  (å­˜æ”¾æ‰€æœ‰ TensorBoard æ—¥å¿—çš„çˆ¶ç›®å½•)
|-- local_data/            (å¯é€‰ï¼Œå­˜æ”¾æœ¬åœ°æ•°æ®é›†)

=====================================================================================
"""

import gradio as gr
import torch
import os
import subprocess
import time
import json
from pathlib import Path

# æé«˜ PyTorch Dynamo çš„é‡ç¼–è¯‘å®¹å¿ä¸Šé™ï¼Œä»¥é¿å…å› å¯å˜æ•°æ®å½¢çŠ¶å¯¼è‡´çš„æŠ¥é”™ã€‚
# è¿™å¯¹äº Gemma3 ç­‰æ–°æ¨¡å‹åœ¨å¤„ç†ä¸åŒé•¿åº¦åºåˆ—æ—¶å°¤å…¶é‡è¦ã€‚
torch._dynamo.config.recompile_limit = 100

# æ ¸å¿ƒåº“å¯¼å…¥
from unsloth import FastLanguageModel
from transformers import TrainingArguments
from transformers.integrations import TensorBoardCallback
from trl import SFTTrainer
from datasets import load_dataset, concatenate_datasets, load_from_disk


# --- 1. å…¨å±€æ ¸å¿ƒé…ç½® ---
LOGS_PARENT_DIR = "logs"  # æ‰€æœ‰ TensorBoard æ—¥å¿—çš„çˆ¶ç›®å½•
OUTPUTS_PARENT_DIR = "outputs"  # æ‰€æœ‰æ¨¡å‹è¾“å‡ºå’Œæ–­ç‚¹çš„çˆ¶ç›®å½•
TENSORBOARD_PROC = None  # å…¨å±€å˜é‡ï¼Œç”¨äºæŒæœ‰ TensorBoard çš„åå°è¿›ç¨‹


# --- 2. è¾…åŠ©å‡½æ•°ï¼šé…ç½®åŠ è½½ ---
def load_config_from_json_files(config_path, default_config, error_msg):
    """
    ä¸€ä¸ªé€šç”¨çš„é…ç½®åŠ è½½å‡½æ•°ï¼Œæ™ºèƒ½å¤„ç†å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ã€‚

    Args:
        config_path (Path or str): é…ç½®æ–‡ä»¶æˆ–ç›®å½•çš„è·¯å¾„ã€‚
        default_config (dict): åŠ è½½å¤±è´¥æ—¶è¿”å›çš„é»˜è®¤é…ç½®ã€‚
        error_msg (str): åŠ è½½å¤±è´¥æ—¶æ‰“å°çš„é”™è¯¯ä¿¡æ¯ã€‚

    Returns:
        tuple: (é…ç½®åˆ—è¡¨, ç”¨äºGradioä¸‹æ‹‰æ¡†çš„æ˜¾ç¤ºåç§°åˆ—è¡¨)
    """
    if isinstance(config_path, Path) and config_path.is_dir():
        json_files = list(config_path.glob("*.json"))
        if not json_files:
            print(f"è­¦å‘Š: ç›®å½• '{config_path}' ä¸ºç©ºæˆ–ä¸åŒ…å« .json æ–‡ä»¶ã€‚")
            return [default_config], [default_config.get("display_name", "Default")]
        configs = [json.load(open(f, "r", encoding="utf-8")) for f in json_files]
        return configs, [cfg["display_name"] for cfg in configs]
    elif Path(config_path).is_file():
        with open(config_path, "r", encoding="utf-8") as f:
            configs = json.load(f)
        return configs, [cfg["display_name"] for cfg in configs]
    else:
        print(f"è­¦å‘Š: {error_msg}")
        return [default_config], [default_config.get("display_name", "Default")]


# åº”ç”¨ç¨‹åºå¯åŠ¨æ—¶ï¼ŒåŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†çš„é…ç½®
MODELS_CONFIG, MODEL_DISPLAY_NAMES = load_config_from_json_files(
    Path("models.json"), {}, "æ¨¡å‹é…ç½®æ–‡ä»¶ 'models.json' æœªæ‰¾åˆ°ã€‚"
)
DATASETS_CONFIG, DATASET_DISPLAY_NAMES = load_config_from_json_files(
    Path("datasets_config"), {}, "æ•°æ®é›†é…ç½®ç›®å½• 'datasets_config' æœªæ‰¾åˆ°ã€‚"
)


# --- 3. è¾…åŠ©å‡½æ•°ï¼šå¯åŠ¨ TensorBoard ---
def launch_tensorboard():
    """åœ¨åå°å¯åŠ¨ TensorBoard æœåŠ¡ï¼Œç›‘æ§æ‰€æœ‰å®éªŒçš„çˆ¶æ—¥å¿—ç›®å½•ã€‚"""
    global TENSORBOARD_PROC
    if TENSORBOARD_PROC is not None and TENSORBOARD_PROC.poll() is None:
        return
    os.makedirs(LOGS_PARENT_DIR, exist_ok=True)
    TENSORBOARD_PROC = subprocess.Popen(
        [
            "tensorboard",
            "--logdir",
            LOGS_PARENT_DIR,
            "--host",
            "0.0.0.0",
            "--port",
            "6006",
        ]
    )
    time.sleep(5)  # ç­‰å¾… TensorBoard å¯åŠ¨


# --- 4. è¾…åŠ©å‡½æ•°ï¼šå‡†å¤‡æ•°æ®é›† ---
def prepare_dataset(dataset_config):
    """
    æ ¹æ®å•ä¸ªæ•°æ®é›†çš„é…ç½®ï¼Œæ™ºèƒ½åœ°åŠ è½½æ•°æ®ã€‚
    - å¦‚æœ "is_local": trueï¼Œåˆ™ä»æœ¬åœ°ç£ç›˜åŠ è½½ã€‚
    - å¦åˆ™ï¼Œä» Hugging Face Hub ä¸‹è½½ã€‚
    """
    if dataset_config.get("is_local", False):
        dataset_path = dataset_config["dataset_id"]
        if not Path(dataset_path).exists():
            raise FileNotFoundError(f"æœ¬åœ°æ•°æ®é›†è·¯å¾„æœªæ‰¾åˆ°: {dataset_path}")
        dataset = load_from_disk(dataset_path)
    else:
        dataset = load_dataset(
            dataset_config["dataset_id"], split=dataset_config.get("split", "train")
        )

    # æ ¹æ®æ¨¡æ¿æ ¼å¼åŒ–æ•°æ®é›†
    prompt_template = dataset_config["prompt_template"]
    column_mappings = dataset_config["input_columns"]

    def formatting_prompts_func(examples):
        texts = []
        zipped_columns = zip(
            *(examples[col_name] for col_name in column_mappings.values())
        )
        for values in zipped_columns:
            format_dict = dict(zip(column_mappings.keys(), values))
            texts.append(prompt_template.format(**format_dict))
        return {"text": texts}

    dataset = dataset.map(formatting_prompts_func, batched=True)

    # ä¸ºåŠ é€Ÿæ¼”ç¤ºï¼Œé»˜è®¤ä»…ä½¿ç”¨å‰200ä¸ªæ ·æœ¬ã€‚å¯åœ¨é…ç½®ä¸­å…³é—­ã€‚
    if len(dataset) > 200 and not dataset_config.get("use_full_dataset", False):
        dataset = dataset.select(range(200))
    return dataset


# --- 5. æ ¸å¿ƒåŠŸèƒ½ï¼šæ¨¡å‹è®­ç»ƒå‡½æ•° ---
def train_model(
    # -- å®éªŒç®¡ç† --
    experiment_name,
    resume_training,
    # -- æ¨¡å¼åˆ‡æ¢ --
    training_mode,
    num_epochs,
    max_steps,
    save_steps,
    # -- æ¨¡å‹ä¸æ•°æ® --
    selected_model_name,
    selected_dataset_names,
    # -- LoRA å‚æ•° --
    lora_r,
    lora_alpha,
    # -- æ ¸å¿ƒè®­ç»ƒå‚æ•° --
    batch_size,
    grad_accum,
    optimizer,
    lr,
    # -- Gradio è¿›åº¦æ¡ --
    progress=gr.Progress(track_tqdm=True),
):
    """æ¥æ”¶æ‰€æœ‰UIå‚æ•°å¹¶æ‰§è¡Œå®Œæ•´çš„æ¨¡å‹å¾®è°ƒæµç¨‹ã€‚"""
    # 1. è®¾ç½®å®éªŒè·¯å¾„
    if not experiment_name or not experiment_name.strip():
        return "é”™è¯¯ï¼šå®éªŒåç§°ä¸èƒ½ä¸ºç©ºã€‚"
    experiment_name = experiment_name.strip().replace(" ", "_")
    output_dir = Path(OUTPUTS_PARENT_DIR) / experiment_name
    logging_dir = Path(LOGS_PARENT_DIR) / experiment_name
    progress(0, desc=f"å‡†å¤‡å®éªŒ: {experiment_name}")

    # 2. åŠ è½½å¹¶åˆå¹¶æ•°æ®é›†
    model_config = next(
        (item for item in MODELS_CONFIG if item["display_name"] == selected_model_name),
        None,
    )
    if not model_config or not selected_dataset_names:
        return "é”™è¯¯ï¼šå¿…é¡»é€‰æ‹©ä¸€ä¸ªæ¨¡å‹å’Œè‡³å°‘ä¸€ä¸ªæ•°æ®é›†ã€‚"
    progress(0.1, desc="åŠ è½½å¹¶å¤„ç†æ•°æ®é›†...")
    all_datasets = [
        prepare_dataset(cfg)
        for name in selected_dataset_names
        if (
            cfg := next(
                (item for item in DATASETS_CONFIG if item["display_name"] == name), None
            )
        )
    ]
    if not all_datasets:
        return "é”™è¯¯ï¼šæ— æ³•åŠ è½½æ‰€é€‰çš„æ•°æ®é›†é…ç½®ã€‚"
    progress(0.2, desc=f"åˆå¹¶ {len(all_datasets)} ä¸ªæ•°æ®é›†ä¸­...")
    combined_dataset = concatenate_datasets(all_datasets)

    # 3. åˆå§‹åŒ–æ¨¡å‹å’Œ Tokenizer
    progress(0.3, desc=f"åˆå§‹åŒ–æ¨¡å‹: {model_config['model_id']}...")
    dtype_str = model_config.get("dtype")
    dtype = {"bfloat16": torch.bfloat16, "float16": torch.float16}.get(dtype_str)
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=model_config["model_id"],
        max_seq_length=2048,
        dtype=dtype,
        load_in_4bit=model_config["load_in_4bit"],
    )

    # 4. åº”ç”¨ LoRA (PEFT) é…ç½®
    model = FastLanguageModel.get_peft_model(
        model,
        r=int(lora_r),
        lora_alpha=int(lora_alpha),
        target_modules=[
            "q_proj",
            "k_proj",
            "v_proj",
            "o_proj",
            "gate_proj",
            "up_proj",
            "down_proj",
        ],
        lora_dropout=0,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
    )

    # 5. æ ¹æ®é€‰æ‹©çš„æ¨¡å¼ï¼ŒåŠ¨æ€é…ç½®è®­ç»ƒå‚æ•°
    progress(0.4, desc="é…ç½®è®­ç»ƒå‚æ•°...")
    args = {
        "output_dir": str(output_dir),
        "logging_dir": str(logging_dir),
        "per_device_train_batch_size": int(batch_size),
        "gradient_accumulation_steps": int(grad_accum),
        "learning_rate": float(lr),
        "logging_steps": 1,
        "optim": optimizer,
        "fp16": not torch.cuda.is_bf16_supported(),
        "bf16": torch.cuda.is_bf16_supported(),
        "warmup_steps": 10,
        "weight_decay": 0.01,
        "lr_scheduler_type": "linear",
        "seed": 3407,
        "save_total_limit": 3,
    }

    if training_mode == "æŒ‰è½®æ¬¡ (Epochs)":
        args["num_train_epochs"] = float(num_epochs)
        args["save_strategy"] = "epoch"
    else:  # æŒ‰æ­¥æ•° (Steps)
        args["max_steps"] = int(max_steps)
        args["save_strategy"] = "steps"
        args["save_steps"] = int(save_steps)

    training_args = TrainingArguments(**args)

    # 6. åˆå§‹åŒ–è®­ç»ƒå™¨ (SFTTrainer)
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=combined_dataset,
        dataset_text_field="text",
        max_seq_length=2048,
        dataset_num_proc=2,
        packing=False,
        args=training_args,
        callbacks=[TensorBoardCallback()],
    )

    # 7. å¼€å§‹æˆ–ç»§ç»­è®­ç»ƒ
    status_msg = "ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ..." if resume_training else "å¼€å§‹æ–°çš„è®­ç»ƒ..."
    progress(0.5, desc=status_msg)
    trainer.train(resume_from_checkpoint=resume_training)

    progress(1.0, desc="è®­ç»ƒå®Œæˆï¼")
    return f"è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åœ¨ '{output_dir}'"


# --- 6. Gradio UI ç•Œé¢å®šä¹‰ ---
def update_training_mode_ui(mode):
    """æ ¹æ®é€‰æ‹©çš„è®­ç»ƒæ¨¡å¼ï¼ŒåŠ¨æ€æ›´æ–°UIå…ƒç´ çš„å¯è§æ€§ã€‚"""
    is_epoch_mode = mode == "æŒ‰è½®æ¬¡ (Epochs)"
    return {
        num_epochs_slider: gr.update(visible=is_epoch_mode),
        max_steps_slider: gr.update(visible=not is_epoch_mode),
        save_steps_input: gr.update(visible=not is_epoch_mode),
    }


with gr.Blocks(theme=gr.themes.Soft(), css="footer {display: none !important}") as demo:
    gr.Markdown("# ğŸš€ Unsloth + Gradio + TensorBoard (ç»ˆæç‰ˆ)")
    gr.Markdown("### âœ¨ *é»˜è®¤å‚æ•°å·²ä¸º 8GB VRAM (å¦‚ RTX 3070) ä¼˜åŒ–*")

    with gr.Row():
        # -- å·¦ä¾§ï¼šé…ç½®é¢æ¿ --
        with gr.Column(scale=1):
            gr.Markdown("## âš™ï¸ è®­ç»ƒé…ç½®")

            with gr.Accordion("1. å®éªŒè®¾ç½®", open=True):
                experiment_name_input = gr.Textbox(
                    label="å®éªŒåç§° (å¿…å¡«)", value="8gb-vram-test"
                )
                resume_checkbox = gr.Checkbox(label="ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ", value=False)

            with gr.Accordion("2. æ¨¡å‹ä¸æ•°æ®é›†", open=True):
                model_dropdown = gr.Dropdown(
                    choices=MODEL_DISPLAY_NAMES,
                    value=MODEL_DISPLAY_NAMES[0] if MODEL_DISPLAY_NAMES else None,
                    label="é€‰æ‹©æ¨¡å‹",
                )
                dataset_dropdown = gr.Dropdown(
                    choices=DATASET_DISPLAY_NAMES,
                    value=[DATASET_DISPLAY_NAMES[0]] if DATASET_DISPLAY_NAMES else None,
                    label="é€‰æ‹©æ•°æ®é›† (å¯å¤šé€‰)",
                    multiselect=True,
                )

            with gr.Accordion("3. LoRA å‚æ•° (8GB ä¼˜åŒ–)", open=False):
                lora_r_slider = gr.Slider(4, 64, value=8, step=4, label="LoRA Rank (r)")
                lora_alpha_slider = gr.Slider(
                    4, 128, value=16, step=4, label="LoRA Alpha"
                )

            with gr.Accordion("4. è®­ç»ƒæ ¸å¿ƒå‚æ•° (8GB ä¼˜åŒ–)", open=True):
                training_mode_selector = gr.Radio(
                    ["æŒ‰æ­¥æ•° (Steps)", "æŒ‰è½®æ¬¡ (Epochs)"],
                    value="æŒ‰æ­¥æ•° (Steps)",
                    label="è®­ç»ƒæ¨¡å¼",
                )
                num_epochs_slider = gr.Slider(
                    0.1, 10, value=1, step=0.1, label="è®­ç»ƒè½®æ•° (Epochs)", visible=False
                )
                max_steps_slider = gr.Slider(
                    10,
                    2000,
                    100,
                    step=10,
                    label="æœ€å¤§è®­ç»ƒæ­¥æ•° (Max Steps)",
                    visible=True,
                )
                save_steps_input = gr.Number(
                    value=50, label="æ¯ N æ­¥ä¿å­˜ä¸€æ¬¡æ–­ç‚¹", visible=True
                )

                batch_size_slider = gr.Slider(
                    1, 16, value=1, step=1, label="Batch Size"
                )
                grad_accum_slider = gr.Slider(
                    1, 16, value=8, step=1, label="Gradient Accumulation"
                )
                optimizer_dropdown = gr.Dropdown(
                    ["adamw_8bit", "adamw_torch"], value="adamw_8bit", label="ä¼˜åŒ–å™¨"
                )
                learning_rate_slider = gr.Slider(
                    1e-5, 5e-4, 2e-4, step=1e-5, label="å­¦ä¹ ç‡"
                )

            start_button = gr.Button("âœ… å¼€å§‹è®­ç»ƒ", variant="primary")

        # -- å³ä¾§ï¼šTensorBoard é¢æ¿ --
        with gr.Column(scale=3):
            gr.Markdown("## ğŸ“Š TensorBoard ç›‘æ§é¢æ¿")
            tensorboard_html = f'<iframe src="http://127.0.0.1:6006" width="100%" height="800px" frameborder="0"></iframe>'
            tensorboard_view = gr.HTML(tensorboard_html)

    # -- åº•éƒ¨ï¼šçŠ¶æ€è¾“å‡ºåŒºåŸŸ --
    gr.Markdown("--- \n ## ğŸ“‹ è®­ç»ƒæ—¥å¿—ä¸çŠ¶æ€")
    status_output = gr.Textbox(label="Status", interactive=False, lines=3, max_lines=5)

    # -- äº‹ä»¶ç»‘å®š --
    # ç»‘å®šè®­ç»ƒæ¨¡å¼å•é€‰æ¡†çš„ change äº‹ä»¶ï¼Œç”¨äºæ›´æ–°UI
    training_mode_selector.change(
        fn=update_training_mode_ui,
        inputs=training_mode_selector,
        outputs=[num_epochs_slider, max_steps_slider, save_steps_input],
    )

    # æ”¶é›†æ‰€æœ‰è¾“å…¥ç»„ä»¶ï¼Œå¹¶ç»‘å®šåˆ°â€œå¼€å§‹è®­ç»ƒâ€æŒ‰é’®çš„ click äº‹ä»¶
    all_inputs = [
        experiment_name_input,
        resume_checkbox,
        training_mode_selector,
        num_epochs_slider,
        max_steps_slider,
        save_steps_input,
        model_dropdown,
        dataset_dropdown,
        lora_r_slider,
        lora_alpha_slider,
        batch_size_slider,
        grad_accum_slider,
        optimizer_dropdown,
        learning_rate_slider,
    ]
    start_button.click(fn=train_model, inputs=all_inputs, outputs=[status_output])

    # Gradio åº”ç”¨åŠ è½½æ—¶ï¼Œè‡ªåŠ¨åœ¨åå°å¯åŠ¨ TensorBoard
    demo.load(fn=launch_tensorboard)

# --- 7. å¯åŠ¨åº”ç”¨ ---
if __name__ == "__main__":
    # share=True ä¼šç”Ÿæˆä¸€ä¸ªå…¬å…±é“¾æ¥ï¼Œæ–¹ä¾¿åœ¨ä»»ä½•åœ°æ–¹è®¿é—®
    demo.launch(share=True)
